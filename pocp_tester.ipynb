{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "'''\n",
      "pocp - automatic monitoring of New Zealand planned outage and coordination process\n",
      "    Copyright (C) 2013 David Hume, Electricty Authority, New Zealand.\n",
      "\n",
      "Initial POCP version control script currently running with the following two crontab entries:\n",
      "\n",
      "5 1,7,13,19 * * * /usr/bin/python /home/humed/python/POCP/pocp.py --pocp_pass=\"password\" --dw_pass=\"password\" >> /home/humed/python/POCP/pocp_cron.log 2>&1\n",
      "10 1,7,13,19 * * * cd /home/humed/python/POCP && /usr/local/bin/git commit -a -m \"Cron commit at $(date +\\%Y_\\%m_\\%d_\\%H)\" >> /home/hume$\n",
      "\n",
      "The first part runs this python script every 6 hours at five minutes past the hour, for the hours, 1am,7am,1pm and 7pm.\n",
      "This script is currently basic and needs to be rewritten in a proper class format with exception handling etc, (future work) \n",
      "The basic idea is: 1) grab all POCP data (confirmed/tentative/cancelled) for Transmission/Generation, and, \n",
      "                      Direct Connects looking back 6 months and forward 6 months from the current date\n",
      "                   2) add this data to the all time pocp data history and remove duplicates\n",
      "                   3) save this to a text file, in this case, pocp_all.csv\n",
      "                   4) modify the generation POCP data to be more usefull historically - see code below\n",
      "                   5) create time series data with POCP_to_timeseries function\n",
      "                   6) output csv files for interative plotting with d3/javascript, see, pocp.html\n",
      "                    \n",
      "D J Hume, 8 May, 2013\n",
      "'''"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "TODO/Ideas: This notebook is a work in progress attempting th develop and munge the POCP data into better form for plotting\n",
      "    with d3/crossfilter\n",
      "\n",
      "A couple of current ideas before I forget (18/9/2013)\n",
      "Generation, live stack plots of generation outages with time/NI/SI/gen_type\n",
      "Update total stack plots (as we used to do)\n",
      "\n",
      "Transmission:\n",
      "    Labeled line plots of current transmission outages with time, sorted by duration, so we have the long duration outahes at the bottom\n",
      "    Kinda similar to above...\n",
      "    \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import mechanize\n",
      "from bs4 import BeautifulSoup\n",
      "import os,sys\n",
      "from datetime import date, datetime, time, timedelta\n",
      "from io import StringIO\n",
      "import pyodbc\n",
      "import pandas.io.sql as sql\n",
      "from dateutil.parser import parse\n",
      "import matplotlib as mpl\n",
      "import matplotlib.pyplot as plt\n",
      "import argparse\n",
      "import numpy as np\n",
      "import EAtools as ea"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#############################################################################################################################################################################        \n",
      "#Setup command line option and argument parsing\n",
      "#############################################################################################################################################################################        \n",
      "parser = argparse.ArgumentParser(add_help=False)\n",
      "parser.add_argument('--pocp_host', action=\"store\",dest='pocp_host',default='http://pocp.redspider.co.nz/')\n",
      "parser.add_argument('--pocp_user', action=\"store\",dest='pocp_user',default='david.hume')\n",
      "parser.add_argument('--pocp_pass', action=\"store\",dest='pocp_pass')\n",
      "parser.add_argument('--dw_user', action=\"store\",dest='dw_user',default='linux_user')\n",
      "parser.add_argument('--dw_pass', action=\"store\",dest='dw_pass')\n",
      "parser.add_argument('--pocp_path', action=\"store\",dest='pocp_path',default='/home/humed/python/POCP/')\n",
      "\n",
      "IPy_notebook = True\n",
      "if IPy_notebook == False:\n",
      "    cmd_line = parser.parse_args()\n",
      "if IPy_notebook == True:\n",
      "    ea.set_options()\n",
      "    class cmd_line():\n",
      "        def __init__(self,pocp_host,pocp_user,pocp_pass,dw_user,dw_pass,pocp_path):\n",
      "            self.pocp_host = pocp_host\n",
      "            self.pocp_user = pocp_user\n",
      "            self.pocp_pass = pocp_pass\n",
      "            self.dw_user = dw_user\n",
      "            self.dw_pass = dw_pass\n",
      "            self.pocp_path = pocp_path\n",
      "            \n",
      "            \n",
      "    cmd_line=cmd_line('http://pocp.redspider.co.nz/','username_here','password_here','linux_user','linux','/home/humed/python/POCP/')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "############################################################################################################################################################################        \n",
      "#Download the the last year of ther POCP database, append to historical data and spit out a csv\n",
      "#############################################################################################################################################################################        \n",
      "\n",
      "class POCP(object):\n",
      "    '''This is the POCP class'''\n",
      "    def __init__(self,cmd_line,start_time=None,end_time=None):\n",
      "        self.cmd_line = cmd_line\n",
      "        self.start_time = start_time\n",
      "        self.end_time = end_time\n",
      "        self.current_download = None\n",
      "        self.con = ea.DW_connect(linux=True)\n",
      "        self.additional_island_mappings= {'ANC':'NI','KAG':'NI','KTW':'NI','NAP':'NI','PRI':'NI',\n",
      "                                              'TAA':'NI','TAP':'NI','TUK':'NI','WHL':'SI','WWD':'NI','THI':'NI','n/a':nan}\n",
      "        self.additional_gentype_mappings= {'ABY': 'Hydro','ANC': 'Thermal','BLN': 'Hydro','BPE': 'Wind',\\\n",
      "                                               'BRB': 'Thermal','CST': 'Hydro','DOB': 'Hydro','HAM': 'Thermal',\\\n",
      "                                               'HKK': 'Hydro','HUI': 'Hydro','HWB': 'Wind','KAG': 'Geothermal',\\\n",
      "                                               'KOE':'Geothermal','KTW': 'Hydro','KUM': 'Hydro','LTN': 'Wind',\\\n",
      "                                               'NSY': 'Hydro','PRI': 'Hydro','TAA': 'Geothermal','TAP': 'Wind',\\\n",
      "                                               'TGA': 'Hydro','TUK': 'Wind','WHL': 'Wind','THI':'Geothermal','n/a':nan}\n",
      "    #mappings\n",
      "    def generation_type_map(self):\n",
      "        gens = sql.read_frame(\"Select * from com.MAP_Generating_plant\", self.con)\n",
      "        gens = gens[gens['Connection_Type']=='G']\n",
      "        GT = gens.set_index('POC').Generation_Type.reset_index()\n",
      "        GT['POC'] = GT.POC.map(lambda x: x[0:3])\n",
      "        GT = GT.drop_duplicates().set_index('POC').Generation_Type\n",
      "        GT.ix['KAW'] = 'Geothermal'\n",
      "        self.GT = GT.to_dict()\n",
      "        self.GT = dict(self.GT.items()+self.additional_gentype_mappings.items())\n",
      "        \n",
      "    def island_map(self):\n",
      "        island = sql.read_frame(\"Select * from com.MAP_PNode_to_POC_and_island\", self.con)\n",
      "        island_map = island.set_index('POC').Island\n",
      "        island_map.index=island_map.index.map(lambda x: x[0:3])\n",
      "        self.island_map = island_map.reset_index().drop_duplicates().set_index('index').Island.to_dict()\n",
      "        self.island_map = dict(self.island_map.items()+self.additional_island_mappings.items())\n",
      "    \n",
      "    def mappings(self,df):\n",
      "        self.island_map()\n",
      "        self.generation_type_map()\n",
      "        df['Generation type'] = df.GIP.map(lambda x: self.GT[x])\n",
      "        df['Island'] = df.GIP.map(lambda x: self.island_map[x])\n",
      "        return df   \n",
      "    \n",
      "    def dt_convert(self,x):\n",
      "        if isinstance(x, basestring):\n",
      "            date = x.split(' ')[0].split('-')\n",
      "            time = x.split(' ')[1].split(':')\n",
      "            return datetime(int(date[0]),int(date[1]),int(date[2]),int(time[0]),int(time[1]),int(time[2]))\n",
      "        else:\n",
      "            return x\n",
      "\n",
      "    def set_date_range(self): #Note: downloads from the POCP redspider server appear to be limited to 10000 rows max.\n",
      "        if self.start_time is None:\n",
      "            self.strt = (datetime.now() - timedelta(.5*365)) #~6 months back from now\n",
      "            self.start_time = self.strt.isoformat().split('T')[0].split('-')[2] + '/' + \\\n",
      "                              self.strt.isoformat().split('T')[0].split('-')[1] + '/' + \\\n",
      "                              self.strt.isoformat().split('T')[0].split('-')[0]\n",
      "        if self.end_time is None:\n",
      "            self.endt = (datetime.now() + timedelta(0.5*365)) #~6 months into the future\n",
      "            self.end_time = self.endt.isoformat().split('T')[0].split('-')[2] + '/' + \\\n",
      "                            self.endt.isoformat().split('T')[0].split('-')[1] + '/' + \\\n",
      "                            self.endt.isoformat().split('T')[0].split('-')[0]\n",
      "\n",
      "    def download_pocp(self): #Note: downloads from the POCP redspider server appear to be limited to 10000 rows max.\n",
      "        def POCP_date_parser(datestr):\n",
      "            d=datestr.replace('/',' ').replace(':',' ').split(' ')\n",
      "            return datetime(int('20' + d[2]),int(d[1]),int(d[0]),int(d[3]),int(d[4]))\n",
      "\n",
      "        print 'Getting POCP between ' + self.start_time + ' and ' + self.end_time\n",
      "        \n",
      "        bufferIO = StringIO()\n",
      "\n",
      "        br=mechanize.Browser(factory=mechanize.RobustFactory())\n",
      "        br.set_handle_refresh(mechanize._http.HTTPRefreshProcessor(), max_time=1) # Follows refresh 0 but not hangs on refresh > 0\n",
      "        br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')] # User-Agent (this is cheating, ok?)\n",
      "        r=br.open(cmd_line.pocp_host)\n",
      "        br.select_form(nr=0)\n",
      "        br.submit()  #click I agree\n",
      "        br.select_form(nr=0)     #Now login\n",
      "        br['email'] = cmd_line.pocp_user\n",
      "        br['password'] = cmd_line.pocp_pass\n",
      "        br.submit()  #submit user name and password.\n",
      "        br.select_form(nr=0)     #select form \n",
      "        br['sview'] = ['excel']  #select \"excel\" although this is in fact a tab delimited table\n",
      "        br['start'] = self.start_time #set start and end times from above\n",
      "        br['end'] = self.end_time\n",
      "        br['planning_status_id[]'] = ['1','2','3'] #['1','2','3']\n",
      "        response = br.submit()   #submit the search/download for all POCP data between start_time and end_time, save as response\n",
      "        bufferIO = StringIO()    #Open a string buffer object, write the POCP database to this then read_csv the data...\n",
      "        bufferIO.write(unicode(response.read())) \n",
      "        bufferIO.seek(0)\n",
      "        current_download = pd.read_csv(bufferIO,parse_dates=['Start','End','Last Modified'],\\\n",
      "                                       date_parser=POCP_date_parser,sep='\\t',index_col=0)\n",
      "        return self.current_download\n",
      "\n",
      "    def append_pocp(self,pocp):    \n",
      "        P_all = pd.read_csv(self.cmd_line.pocp_path + 'pocp_all.csv',index_col=0)\n",
      "        self.P = pd.concat([P_all, self.current_download])   #add latest download \n",
      "        self.P['End'] = self.P.End.map(lambda x: p.dt_convert(x)) #convert datetimes.\n",
      "        self.P['Start'] = self.P.Start.map(lambda x: p.dt_convert(x))\n",
      "        self.P['Last Modified'] = self.P['Last Modified'].map(lambda x: p.dt_convert(x))\n",
      "        self.P = self.P.drop_duplicates()    #and drop any duplicates\n",
      "        self.P.to_csv(self.cmd_line.pocp_path + 'pocp_all.csv') #save the updated POCP database as a csv (good for looking a diffs using gitk)\n",
      "        return self.P\n",
      "\n",
      "    def POCP_logic(self,outage_history=False): #this is our main POCP grabber, with addition complex logic to try and get what we want, with a few assumptions thrown in for good measure...\n",
      "        def POCP_get():\n",
      "            def get(tdc):\n",
      "                X=self.P[self.P.Category==tdc]\n",
      "                Xbool = (X['Start']<=self.end_time) & (X['End']>=self.start_time) #ok, all outages between start and end including those that have been cancelled\n",
      "                X = X[Xbool]\n",
      "                X['Duration'] = X.End-X.Start\n",
      "                if tdc == 'Transmission':\n",
      "                    del X['MW remaining']\n",
      "                    del X['MW Loss']\n",
      "                    del X['MV remaining']\n",
      "                if tdc == 'Generation':\n",
      "                    del X['Nature']\n",
      "                    X['NP_MWh']=X['Duration'].map(lambda x: x/np.timedelta64(1, 's')/3600) * X['MW Loss']\n",
      "                    X=X.sort(columns=['NP_MWh'],ascending = False)\n",
      "                del X['Category']\n",
      "                return X \n",
      "            T = get('Transmission')\n",
      "            G = get('Generation')\n",
      "            D = get('Direct Connection')\n",
      "            if outage_history == True:\n",
      "               if not T.empty:\n",
      "                   T = T.reset_index().set_index(['id','Last Modified'],drop=False).sortlevel(0)\n",
      "               if not G.empty:\n",
      "                   G = G.reset_index().set_index(['id','Last Modified'],drop=False).sort(columns='MW Loss',ascending=False).sortlevel(0)\n",
      "               if not D.empty:\n",
      "                   D = D.reset_index().set_index(['id','Last Modified'],drop=False).sortlevel(0)\n",
      "            elif outage_history == False: #this is what you should see in the current pocp database that is now version controlled.\n",
      "               if not T.empty:\n",
      "                   IXT = T.reset_index().groupby('id')['Last Modified'].max() #groupby id, as there will be an entry for each iteration of the outage, then get return the most recent time for that id group,\n",
      "                   T=T.reset_index().set_index(['id','Last Modified'],drop=False).ix[zip(IXT.to_dict().keys(),IXT.to_dict().values()),:] #then we select the rows, in this case, of a multi-indexed dataframe using the above outage ID and most recent modified time in IX.\n",
      "               if not G.empty:\n",
      "                   IXG = G.reset_index().groupby('id')['Last Modified'].max()\n",
      "                   G=G.reset_index().set_index(['id','Last Modified'],drop=False).ix[zip(IXG.to_dict().keys(),IXG.to_dict().values()),:] #then we select the rows, in this case, of a multi-indexed dataframe using the above outage ID and most recent modified time in IX.\n",
      "                   G=G.sort(columns='MW Loss',ascending=False)\n",
      "               if not D.empty:\n",
      "                   IXD = D.reset_index().groupby('id')['Last Modified'].max() \n",
      "                   D=D.reset_index().set_index(['id','Last Modified']).ix[zip(IXD.to_dict().keys(),IXD.to_dict().values()),:] #then we select the rows, in this case, of a multi-indexed dataframe using the above outage ID and most recent modified time in IX.\n",
      "            return T,G,D\n",
      "        \n",
      "        def add_caned_after_start(df):\n",
      "            caned=df[df['Planning Status']=='Cancelled'] #look at the cancelled entrys\n",
      "            caned = caned[caned.index.map(lambda x: x[1])>caned.Start.tolist()] #if cancelled after Start time then keep\n",
      "            confirmed=df[df['Planning Status']=='Confirmed'] #confirmed, and\n",
      "            tentative=df[df['Planning Status']=='Tentative'] #tentative\n",
      "            df=confirmed.append(caned) #append confirmed outages with those that have been cancelled after the outage window ended\n",
      "            #df = df.append(tentative).sort() #also append all tentative outages, then sort.\n",
      "            df['GIP/GXPs']=df['GIP/GXPs'].map(lambda x: x[0:3])\n",
      "            df['GIP/GXPs'][df['GIP/GXPs']=='#N/']='NAP'\n",
      "            df = df.rename(columns={'GIP/GXPs':'GIP'})\n",
      "            #df = df.dropna(how='any')\n",
      "            #df['Island'] = df.GIP.map(lambda x: island_map2[x])\n",
      "            #dfn=df[df['Island']=='North']\n",
      "            #dfs=df[df['Island']=='South']\n",
      "\n",
      "            if 'MW Loss' in df.columns:\n",
      "                df = df[df['MW Loss']>=0]\n",
      "                df = df.ix[:,['Start','End','MW Loss','Outage Block','GIP','Owner','Nature','Type','Duration','Planning Status']]\n",
      "            else: \n",
      "                df = df.ix[:,['Start','End','Outage Block','GIP','Owner','Nature','Type','Duration','Planning Status']]\n",
      "\n",
      "            df = df.fillna(0)\n",
      "            return df\n",
      "\n",
      "        T,G,D = POCP_get() #get all history\n",
      "        \n",
      "        self.G = add_caned_after_start(G)\n",
      "        self.T = add_caned_after_start(T)\n",
      "        #self.D = add_caned_after_start(D)\n",
      "\n",
      "    def today(self,df):\n",
      "        current_bool = (df['Start']<=datetime.today()) & (df['End']>=(datetime.today())) \n",
      "        df = df[current_bool]\n",
      "        df = df[df['Planning Status'] == 'Confirmed']\n",
      "        df = df.drop_duplicates()\n",
      "        df = df.groupby(level=0).tail(1) #return the last modified entry...\n",
      "        return df\n",
      "\n",
      "    def now(self,df):\n",
      "        current_bool = (df['Start']<=datetime.now()) & (df['End']>=(datetime.now())) \n",
      "        df = df[current_bool]\n",
      "        df = df[df['Planning Status'] == 'Confirmed']\n",
      "        df = df.drop_duplicates()\n",
      "        df = df.groupby(level=0).tail(1) #return the last modified entry...\n",
      "        return df\n",
      "\n",
      "    def timeserializer(self,df):\n",
      "        def ts(x):\n",
      "            i = pd.date_range(x['Start'],x['End']-timedelta(minutes=1), freq='30min')\n",
      "            if 'MW Loss' in x:\n",
      "                s = pd.Series(float(x['MW Loss']),i)\n",
      "                return s\n",
      "        df_ts = df.apply(ts,axis=1).drop_duplicates().sum(axis=0).sort_index()\n",
      "        return df_ts.ix[self.strt.date():self.endt.date()]\n",
      "\n",
      "    def main(self):\n",
      "        outage_history=False\n",
      "        self.set_date_range() #set the start and end times\n",
      "        self.download_pocp() #download POCP over the data range\n",
      "        self.append_pocp(self.current_download) #append current download to the historic POCP data and save.\n",
      "        self.POCP_logic(outage_history=outage_history)\n",
      "        self.G = self.mappings(self.G)\n",
      "        self.Tn = self.now(self.T)\n",
      "        self.Gn = self.now(self.G)\n",
      "        self.Tt = self.today(self.T)\n",
      "        self.Gt = self.today(self.G)\n",
      "\n",
      "        #self.mappings(self.Gc)  #add generation type and island mappings to outage data\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p=POCP(cmd_line)         #the POCP instance\n",
      "p.main()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Getting POCP between 07/05/2013 and 07/05/2014\n"
       ]
      }
     ],
     "prompt_number": 17
    }
   ],
   "metadata": {}
  }
 ]
}